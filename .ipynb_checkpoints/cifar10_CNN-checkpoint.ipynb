{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import ssl\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Required to prevent urlopen error where certificate has expired\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.6, 0.6, 0.6), (0.2, 0.2, 0.2), (0.2, 0.2, 0.2))])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(seed)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2, generator=gen)\n",
    "\n",
    "valset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, generator=gen)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, generator=gen)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859335a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "# transpose image RGB channels so it can be viewed in color\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672099b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits\n",
    "    \n",
    "# single hidden layer convolutional neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # input 3 channel images, output 6 channel images, kernel size 5x5\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 2x2 pooling\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = AlexNet(10)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)  \n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6edf41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(40):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5b5e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(valloader)\n",
    "nextData = next(dataiter)\n",
    "images, labels = nextData[0].to(device), nextData[1].to(device)\n",
    "\n",
    "# print images\n",
    "\n",
    "print([classes[labels[j]] for j in range(4)])\n",
    "\n",
    "# convert to using CPU instead of GPU since it's not compatible for imshow\n",
    "normalImages, normalLabels = images.to(torch.device('cpu')), labels.to(torch.device('cpu'))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(normalImages))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[normalLabels[j]]:5s}' for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "# ignore first value\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792dc534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in valloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee40618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595a122",
   "metadata": {},
   "source": [
    "For 30 output channel images (60 output on the second conv2d):\n",
    "\n",
    "Accuracy of the network on the 10000 test images: 61 %\n",
    "\n",
    "Accuracy for class: plane is 46.2 %\n",
    "\n",
    "Accuracy for class: car   is 83.4 %\n",
    "\n",
    "Accuracy for class: bird  is 45.7 %\n",
    "\n",
    "Accuracy for class: cat   is 33.0 %\n",
    "\n",
    "Accuracy for class: deer  is 50.1 %\n",
    "\n",
    "Accuracy for class: dog   is 50.5 %\n",
    "\n",
    "Accuracy for class: frog  is 83.6 %\n",
    "\n",
    "Accuracy for class: horse is 67.7 %\n",
    "\n",
    "Accuracy for class: ship  is 90.2 %\n",
    "\n",
    "Accuracy for class: truck is 61.7 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4f3c1",
   "metadata": {},
   "source": [
    "For 1050 output channel images (2150 output on the second conv2d):\n",
    "\n",
    "Accuracy of the network on the 10000 test images: 66 %\n",
    "    \n",
    "Accuracy for class: plane is 79.3 %\n",
    "    \n",
    "Accuracy for class: car   is 83.3 %\n",
    "    \n",
    "Accuracy for class: bird  is 35.5 %\n",
    "    \n",
    "Accuracy for class: cat   is 52.8 %\n",
    "    \n",
    "Accuracy for class: deer  is 46.5 %\n",
    "    \n",
    "Accuracy for class: dog   is 45.6 %\n",
    "    \n",
    "Accuracy for class: frog  is 88.1 %\n",
    "    \n",
    "Accuracy for class: horse is 75.4 %\n",
    "    \n",
    "Accuracy for class: ship  is 81.9 %\n",
    "    \n",
    "Accuracy for class: truck is 76.8 %\n",
    "\n",
    "[1,  2000] loss: 1.884\n",
    "    \n",
    "[1,  4000] loss: 1.577\n",
    "    \n",
    "[1,  6000] loss: 1.419\n",
    "    \n",
    "[1,  8000] loss: 1.320\n",
    "    \n",
    "[1, 10000] loss: 1.255\n",
    "    \n",
    "[1, 12000] loss: 1.200\n",
    "    \n",
    "[2,  2000] loss: 1.078\n",
    "    \n",
    "[2,  4000] loss: 1.035\n",
    "    \n",
    "[2,  6000] loss: 1.041\n",
    "    \n",
    "[2,  8000] loss: 0.995\n",
    "    \n",
    "[2, 10000] loss: 0.992\n",
    "    \n",
    "[2, 12000] loss: 0.940\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa4e9b",
   "metadata": {},
   "source": [
    "For 6 output channel images (6 output on second conv2d):\n",
    "\n",
    "Accuracy of the network on the 10000 test images: 54 %\n",
    "\n",
    "Accuracy for class: plane is 61.9 %\n",
    "\n",
    "Accuracy for class: car   is 77.6 %\n",
    "\n",
    "Accuracy for class: bird  is 31.5 %\n",
    "\n",
    "Accuracy for class: cat   is 29.3 %\n",
    "\n",
    "Accuracy for class: deer  is 52.7 %\n",
    "\n",
    "Accuracy for class: dog   is 47.9 %\n",
    "\n",
    "Accuracy for class: frog  is 62.6 %\n",
    "\n",
    "Accuracy for class: horse is 64.2 %\n",
    "\n",
    "Accuracy for class: ship  is 66.4 %\n",
    "\n",
    "Accuracy for class: truck is 48.3 %\n",
    "\n",
    "[1,  2000] loss: 2.042\n",
    "\n",
    "[1,  4000] loss: 1.713\n",
    "\n",
    "[1,  6000] loss: 1.625\n",
    "\n",
    "[1,  8000] loss: 1.558\n",
    "\n",
    "[1, 10000] loss: 1.496\n",
    "\n",
    "[1, 12000] loss: 1.472\n",
    "\n",
    "[2,  2000] loss: 1.396\n",
    "\n",
    "[2,  4000] loss: 1.396\n",
    "\n",
    "[2,  6000] loss: 1.355\n",
    "\n",
    "[2,  8000] loss: 1.348\n",
    "\n",
    "[2, 10000] loss: 1.341\n",
    "\n",
    "[2, 12000] loss: 1.316\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cc490",
   "metadata": {},
   "source": [
    "For 600 output channel images (1200 output on second conv2d):\n",
    "\n",
    "Accuracy of the network on the 10000 test images: 67 %\n",
    "\n",
    "Accuracy for class: plane is 71.7 %\n",
    "\n",
    "Accuracy for class: car   is 75.1 %\n",
    "\n",
    "Accuracy for class: bird  is 64.1 %\n",
    "\n",
    "Accuracy for class: cat   is 42.1 %\n",
    "\n",
    "Accuracy for class: deer  is 67.6 %\n",
    "\n",
    "Accuracy for class: dog   is 41.8 %\n",
    "\n",
    "Accuracy for class: frog  is 71.6 %\n",
    "\n",
    "Accuracy for class: horse is 79.4 %\n",
    "\n",
    "Accuracy for class: ship  is 84.3 %\n",
    "\n",
    "Accuracy for class: truck is 80.8 %\n",
    "\n",
    "[1,  2000] loss: 1.889\n",
    "\n",
    "[1,  4000] loss: 1.538\n",
    "\n",
    "[1,  6000] loss: 1.402\n",
    "\n",
    "[1,  8000] loss: 1.343\n",
    "\n",
    "[1, 10000] loss: 1.248\n",
    "\n",
    "[1, 12000] loss: 1.178\n",
    "\n",
    "[2,  2000] loss: 1.043\n",
    "\n",
    "[2,  4000] loss: 1.049\n",
    "\n",
    "[2,  6000] loss: 1.000\n",
    "\n",
    "[2,  8000] loss: 0.962\n",
    "\n",
    "[2, 10000] loss: 0.981\n",
    "\n",
    "[2, 12000] loss: 0.920\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257ffb1",
   "metadata": {},
   "source": [
    "For 90 output channel images (180 output on second conv2d):\n",
    "\n",
    "Accuracy of the network on the 10000 test images: 70 %\n",
    "\n",
    "Accuracy for class: plane is 61.7 %\n",
    "\n",
    "Accuracy for class: car   is 79.2 %\n",
    "\n",
    "Accuracy for class: bird  is 65.8 %\n",
    "\n",
    "Accuracy for class: cat   is 52.5 %\n",
    "\n",
    "Accuracy for class: deer  is 63.0 %\n",
    "\n",
    "Accuracy for class: dog   is 54.8 %\n",
    "\n",
    "Accuracy for class: frog  is 84.0 %\n",
    "\n",
    "Accuracy for class: horse is 76.3 %\n",
    "\n",
    "Accuracy for class: ship  is 85.4 %\n",
    "\n",
    "Accuracy for class: truck is 85.7 %\n",
    "\n",
    "[1,  2000] loss: 2.039\n",
    "\n",
    "[1,  4000] loss: 1.645\n",
    "\n",
    "[1,  6000] loss: 1.483\n",
    "\n",
    "[1,  8000] loss: 1.405\n",
    "\n",
    "[1, 10000] loss: 1.292\n",
    "\n",
    "[1, 12000] loss: 1.226\n",
    "\n",
    "[2,  2000] loss: 1.106\n",
    "\n",
    "[2,  4000] loss: 1.089\n",
    "\n",
    "[2,  6000] loss: 1.039\n",
    "\n",
    "[2,  8000] loss: 1.004\n",
    "\n",
    "[2, 10000] loss: 0.973\n",
    "\n",
    "[2, 12000] loss: 0.964\n",
    "\n",
    "[3,  2000] loss: 0.807\n",
    "\n",
    "[3,  4000] loss: 0.817\n",
    "\n",
    "[3,  6000] loss: 0.820\n",
    "\n",
    "[3,  8000] loss: 0.806\n",
    "\n",
    "[3, 10000] loss: 0.810\n",
    "\n",
    "[3, 12000] loss: 0.803\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adaee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
